{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 91497,
          "databundleVersionId": 11018643,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30886,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "March ML Mania 2025 - Brier Score Prediction",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "7hNx44gCJ2iO"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "march_machine_learning_mania_2025_path = kagglehub.competition_download('march-machine-learning-mania-2025')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "WqUnkdsjJ2iO"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"display: flex; justify-content: space-between; align-items: flex-start;\">\n",
        "    <div style=\"text-align: left;\">\n",
        "        <p style=\"color:#FFD700; font-size: 15px; font-weight: bold; margin-bottom: 1px; text-align: left;\">Published on  February 13, 2025</p>\n",
        "        <h4 style=\"color:#4B0082; font-weight: bold; text-align: left; margin-top: 6px;\">Author: Jocelyn C. Dumlao</h4>\n",
        "        <p style=\"font-size: 17px; line-height: 1.7; color: #333; text-align: center; margin-top: 20px;\"></p>\n",
        "        <a href=\"https://www.linkedin.com/in/jocelyn-dumlao-168921a8/\" target=\"_blank\" style=\"display: inline-block; background-color: #003f88; color: #fff; text-decoration: none; padding: 5px 10px; border-radius: 10px; margin: 15px;\">LinkedIn</a>\n",
        "        <a href=\"https://github.com/jcdumlao14\" target=\"_blank\" style=\"display: inline-block; background-color: transparent; color: #059c99; text-decoration: none; padding: 5px 10px; border-radius: 10px; margin: 15px; border: 2px solid #007bff;\">GitHub</a>\n",
        "        <a href=\"https://www.youtube.com/@CogniCraftedMinds\" target=\"_blank\" style=\"display: inline-block; background-color: #ff0054; color: #fff; text-decoration: none; padding: 5px 10px; border-radius: 10px; margin: 15px;\">YouTube</a>\n",
        "        <a href=\"https://www.kaggle.com/jocelyndumlao\" target=\"_blank\" style=\"display: inline-block; background-color: #3a86ff; color: #fff; text-decoration: none; padding: 5px 10px; border-radius: 10px; margin: 15px;\">Kaggle</a>\n",
        "    </div>\n",
        "</div>"
      ],
      "metadata": {
        "id": "sQn7WtrXJ2iP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Welcome!\n",
        "\n",
        "This notebook explores historical NCAA Division I men's and women's basketball data to predict the outcomes of March Madness tournament games. We'll leverage provided datasets containing team information, game results, and tournament seeds to build a predictive model. Data files are prefixed with 'M' for men's, 'W' for women's,and some span both.\n",
        "\n",
        "## Goal:\n",
        "Minimize the Brier score, the evaluation metric for this competition.\n",
        "\n",
        "## Approach:\n",
        " 1. Start with a basic model using seed differences.\n",
        " 2. Gradually incorporate more sophisticated features and techniques.\n"
      ],
      "metadata": {
        "id": "b9v9N_kRJ2iQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"padding:10px;background-color:#00ffc3;margin:0;color:#102d02;font-family:newtimeroman;font-size:100%;text-align:center;border-radius:15px 50px;overflow:hidden;font-weight:500;border: 3px solid #00a5a0;\">Brier Score</p>\n",
        "\n",
        "\n",
        "The **Brier score** is a strictly proper scoring rule that measures the accuracy of probabilistic predictions. For unidimensional predictions, it is strictly equivalent to the mean squared error as applied to predicted probabilities.\n",
        "\n",
        "The Brier score is applicable to tasks in which predictions must assign probabilities to a set of mutually exclusive discrete outcomes or classes. The set of possible outcomes can be either binary or categorical in nature, and the probabilities assigned to this set of outcomes must sum to one (where each individual probability is in the range of 0 to 1). It was proposed by Glenn W. Brier in 1950.[1]\n",
        "\n",
        "The Brier score can be thought of as a cost function. More precisely, across all items\n",
        "i\n",
        "âˆˆ\n",
        "1...\n",
        "N\n",
        "in a set of N predictions, the Brier score measures the mean squared difference between:\n",
        "\n",
        "- The predicted probability assigned to the possible outcomes for item i\n",
        "- The actual outcome\n",
        "o\n",
        "i\n",
        "\n",
        "Therefore, the lower the Brier score is for a set of predictions, the better the predictions are calibrated. Note that the Brier score, in its most common formulation, takes on a value between zero and one, since this is the square of the largest possible difference between a predicted probability (which must be between zero and one) and the actual outcome (which can take on values of only 0 or 1). In the original (1950) formulation of the Brier score, the range is double, from zero to two.\n",
        "\n",
        "The Brier score is appropriate for binary and categorical outcomes that can be structured as true or false, but it is inappropriate for ordinal variables which can take on three or more values.\n",
        "\n",
        "Links: https://en.wikipedia.org/wiki/Brier_score"
      ],
      "metadata": {
        "id": "ZrwZhwa8J2iQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"padding:10px;background-color:#00ffc3;margin:0;color:#102d02;font-family:newtimeroman;font-size:100%;text-align:center;border-radius:15px 50px;overflow:hidden;font-weight:500;border: 3px solid #00a5a0;\">Import Libraries</p>"
      ],
      "metadata": {
        "id": "RWRu3Mk4J2iR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import log_loss, brier_score_loss, mean_squared_error, roc_curve, auc\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T05:09:10.057328Z",
          "iopub.execute_input": "2025-02-20T05:09:10.057593Z",
          "iopub.status.idle": "2025-02-20T05:09:10.868591Z",
          "shell.execute_reply.started": "2025-02-20T05:09:10.057572Z",
          "shell.execute_reply": "2025-02-20T05:09:10.86743Z"
        },
        "id": "84bVTSM8J2iR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"padding:10px;background-color:#00ffc3;margin:0;color:#102d02;font-family:newtimeroman;font-size:100%;text-align:center;border-radius:15px 50px;overflow:hidden;font-weight:500;border: 3px solid #00a5a0;\">Load the Data</p>"
      ],
      "metadata": {
        "id": "rZvbALGBJ2iR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/kaggle/input/march-machine-learning-mania-2025/**'"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T05:10:04.911606Z",
          "iopub.execute_input": "2025-02-20T05:10:04.911913Z",
          "iopub.status.idle": "2025-02-20T05:10:04.915365Z",
          "shell.execute_reply.started": "2025-02-20T05:10:04.911895Z",
          "shell.execute_reply": "2025-02-20T05:10:04.914377Z"
        },
        "id": "f_UE5_veJ2iS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class TournamentPredictor:\n",
        "    def __init__(self, data_dir):\n",
        "        self.data_path = data_dir\n",
        "        self.data = None\n",
        "        self.teams = None\n",
        "        self.seeds = None\n",
        "        self.games = None\n",
        "        self.sub = None\n",
        "        self.gb = None\n",
        "        self.col = None\n",
        "        self.model = None # declare model here.\n",
        "        self.calibration_model = None # declare calibration model here.\n",
        "        self.imputer = SimpleImputer(strategy='mean')\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def load_data(self):\n",
        "        files = glob.glob(self.data_path)\n",
        "        self.data = {p.split('/')[-1].split('.')[0]: pd.read_csv(p, encoding='latin-1') for p in files}\n",
        "\n",
        "        teams = pd.concat([self.data['MTeams'], self.data['WTeams']])\n",
        "        teams_spelling = pd.concat([self.data['MTeamSpellings'], self.data['WTeamSpellings']])\n",
        "        teams_spelling = teams_spelling.groupby(by='TeamID', as_index=False)['TeamNameSpelling'].count()\n",
        "        teams_spelling.columns = ['TeamID', 'TeamNameCount']\n",
        "        self.teams = pd.merge(teams, teams_spelling, how='left', on=['TeamID'])\n",
        "\n",
        "        season_cresults = pd.concat([self.data['MRegularSeasonCompactResults'], self.data['WRegularSeasonCompactResults']])\n",
        "        season_dresults = pd.concat([self.data['MRegularSeasonDetailedResults'], self.data['WRegularSeasonDetailedResults']])\n",
        "        tourney_cresults = pd.concat([self.data['MNCAATourneyCompactResults'], self.data['WNCAATourneyCompactResults']])\n",
        "        tourney_dresults = pd.concat([self.data['MNCAATourneyDetailedResults'], self.data['WNCAATourneyDetailedResults']])\n",
        "\n",
        "        seeds_df = pd.concat([self.data['MNCAATourneySeeds'], self.data['WNCAATourneySeeds']])\n",
        "        self.seeds = {'_'.join(map(str, [int(k1), k2])): int(v[1:3]) for k1, v, k2 in seeds_df[['Season', 'Seed', 'TeamID']].values}\n",
        "\n",
        "        self.sub = self.data['SampleSubmissionStage1']\n",
        "\n",
        "        season_cresults['ST'] = 'S'\n",
        "        season_dresults['ST'] = 'S'\n",
        "        tourney_cresults['ST'] = 'T'\n",
        "        tourney_dresults['ST'] = 'T'\n",
        "\n",
        "        self.games = pd.concat((season_dresults, tourney_dresults), axis=0, ignore_index=True)\n",
        "        self.games['WLoc'] = self.games['WLoc'].map({'A': 1, 'H': 2, 'N': 3})\n",
        "\n",
        "        self.games['ID'] = self.games.apply(lambda r: '_'.join(map(str, [r['Season']] + sorted([r['WTeamID'], r['LTeamID']]))), axis=1)\n",
        "        self.games['IDTeams'] = self.games.apply(lambda r: '_'.join(map(str, sorted([r['WTeamID'], r['LTeamID']]))), axis=1)\n",
        "        self.games['Team1'] = self.games.apply(lambda r: sorted([r['WTeamID'], r['LTeamID']])[0], axis=1)\n",
        "        self.games['Team2'] = self.games.apply(lambda r: sorted([r['WTeamID'], r['LTeamID']])[1], axis=1)\n",
        "        self.games['IDTeam1'] = self.games.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1)\n",
        "        self.games['IDTeam2'] = self.games.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1)\n",
        "        self.games['Team1Seed'] = self.games['IDTeam1'].map(self.seeds).fillna(0)\n",
        "        self.games['Team2Seed'] = self.games['IDTeam2'].map(self.seeds).fillna(0)\n",
        "        self.games['ScoreDiff'] = self.games['WScore'] - self.games['LScore']\n",
        "        self.games['Pred'] = self.games.apply(lambda r: 1.0 if sorted([r['WTeamID'], r['LTeamID']])[0] == r['WTeamID'] else 0.0, axis=1)\n",
        "        self.games['ScoreDiffNorm'] = self.games.apply(lambda r: r['ScoreDiff'] * -1 if r['Pred'] == 0.0 else r['ScoreDiff'], axis=1)\n",
        "        self.games['SeedDiff'] = self.games['Team1Seed'] - self.games['Team2Seed']\n",
        "        self.games = self.games.fillna(-1)\n",
        "\n",
        "        c_score_col = ['NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF']\n",
        "        c_score_agg = ['sum', 'mean', 'median', 'max', 'min', 'std', 'skew', 'nunique']\n",
        "        self.gb = self.games.groupby(by=['IDTeams']).agg({k: c_score_agg for k in c_score_col}).reset_index()\n",
        "        self.gb.columns = [''.join(c) + '_c_score' for c in self.gb.columns]\n",
        "\n",
        "        self.games = self.games[self.games['ST'] == 'T']\n",
        "\n",
        "        self.sub['WLoc'] = 3\n",
        "        self.sub['Season'] = self.sub['ID'].map(lambda x: x.split('_')[0]).astype(int)\n",
        "        self.sub['Team1'] = self.sub['ID'].map(lambda x: x.split('_')[1])\n",
        "        self.sub['Team2'] = self.sub['ID'].map(lambda x: x.split('_')[2])\n",
        "        self.sub['IDTeams'] = self.sub.apply(lambda r: '_'.join(map(str, [r['Team1'], r['Team2']])), axis=1)\n",
        "        self.sub['IDTeam1'] = self.sub.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1)\n",
        "        self.sub['IDTeam2'] = self.sub.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1)\n",
        "        self.sub['Team1Seed'] = self.sub['IDTeam1'].map(self.seeds).fillna(0)\n",
        "        self.sub['Team2Seed'] = self.sub['IDTeam2'].map(self.seeds).fillna(0)\n",
        "        self.sub['SeedDiff'] = self.sub['Team1Seed'] - self.sub['Team2Seed']\n",
        "        self.sub = self.sub.fillna(-1)\n",
        "\n",
        "        self.games = pd.merge(self.games, self.gb, how='left', left_on='IDTeams', right_on='IDTeams_c_score')\n",
        "        self.sub = pd.merge(self.sub, self.gb, how='left', left_on='IDTeams', right_on='IDTeams_c_score')\n",
        "\n",
        "        exclude_cols = ['ID', 'DayNum', 'ST', 'Team1', 'Team2', 'IDTeams', 'IDTeam1', 'IDTeam2', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'NumOT', 'Pred', 'ScoreDiff', 'ScoreDiffNorm', 'WLoc'] + c_score_col\n",
        "        self.col = [c for c in self.games.columns if c not in exclude_cols]\n",
        "        print(\"Data loading and preprocessing completed.\")\n",
        "\n",
        "    def create_models(self):\n",
        "      # Create the models here with the same parameters.\n",
        "      self.model = RandomForestRegressor(\n",
        "          n_estimators=235,\n",
        "          random_state=42,\n",
        "          max_depth=15,\n",
        "          min_samples_split=2,\n",
        "          max_features='sqrt',\n",
        "          n_jobs=-1\n",
        "      )\n",
        "      self.calibration_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, max_depth=10)\n",
        "\n",
        "\n",
        "\n",
        "    def train_model(self):\n",
        "        X = self.games[self.col].fillna(-1)\n",
        "        X_imputed = self.imputer.fit_transform(X)\n",
        "        X_scaled = self.scaler.fit_transform(X_imputed)\n",
        "        y = self.games['Pred']\n",
        "\n",
        "        X_train, X_cal, y_train, y_cal = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        self.model.fit(X_train, y_train)\n",
        "        train_preds = self.model.predict(X_train).clip(0.001, 0.999)\n",
        "\n",
        "        cal_preds = self.model.predict(X_cal).clip(0.001, 0.999)\n",
        "        self.calibration_model.fit(cal_preds.reshape(-1, 1), y_cal)\n",
        "\n",
        "        train_preds_calibrated = self.calibration_model.predict(train_preds.reshape(-1, 1)).clip(0.001, 0.999)\n",
        "\n",
        "        print(f'Log Loss (Train): {log_loss(y_train, train_preds_calibrated):.4f}')\n",
        "        print(f'Brier Score (Train): {brier_score_loss(y_train, train_preds_calibrated):.4f}')\n",
        "        print(f'MSE (Train): {mean_squared_error(y_train, train_preds_calibrated):.4f}')\n",
        "\n",
        "        # Plot ROC Curve for the calibration set.\n",
        "        self.plot_roc_curve(y_cal, cal_preds, \"Calibration Set ROC Curve\")\n",
        "\n",
        "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "        cv_mse_scores = []\n",
        "        cv_logloss_scores = []\n",
        "        for train_index, val_index in kf.split(X_scaled):\n",
        "            X_train, X_val = X_scaled[train_index], X_scaled[val_index]\n",
        "            y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "            self.model.fit(X_train, y_train)\n",
        "            val_preds = self.model.predict(X_val).clip(0.001, 0.999)\n",
        "\n",
        "            self.calibration_model.fit(val_preds.reshape(-1, 1), y_val)\n",
        "            val_preds_calibrated = self.calibration_model.predict(val_preds.reshape(-1, 1)).clip(0.001, 0.999)\n",
        "\n",
        "            mse = mean_squared_error(y_val, val_preds_calibrated)\n",
        "            logloss = log_loss(y_val, val_preds_calibrated)\n",
        "\n",
        "            cv_mse_scores.append(mse)\n",
        "            cv_logloss_scores.append(logloss)\n",
        "\n",
        "        print(f'Cross-validated MSE: {np.mean(cv_mse_scores):.4f}')\n",
        "        print(f'Cross-validated LogLoss: {np.mean(cv_logloss_scores):.4f}')\n",
        "\n",
        "        feature_importances = self.model.feature_importances_\n",
        "        feature_names = self.col\n",
        "        self.plot_feature_importance(feature_importances, feature_names)\n",
        "\n",
        "        self.plot_calibration_curve(y_cal, cal_preds)\n",
        "\n",
        "        # Plot the distribution of calibrated predictions.\n",
        "        self.plot_prediction_distribution(train_preds_calibrated, \"Distribution of Calibrated Training Predictions\")\n",
        "\n",
        "    def predict_submission(self, output_file='submission.csv'):\n",
        "        sub_X = self.sub[self.col].fillna(-1)\n",
        "        sub_X_imputed = self.imputer.transform(sub_X)\n",
        "        sub_X_scaled = self.scaler.transform(sub_X_imputed)\n",
        "\n",
        "        preds = self.model.predict(sub_X_scaled).clip(0.001, 0.999)\n",
        "        preds_calibrated = self.calibration_model.predict(preds.reshape(-1, 1)).clip(0.001, 0.999)\n",
        "\n",
        "        self.sub['Pred'] = preds_calibrated\n",
        "        self.sub[['ID', 'Pred']].to_csv(output_file, index=False)\n",
        "        print(f\"Submission file saved to {output_file}\")\n",
        "\n",
        "    def plot_feature_importance(self, importances, feature_names, top_n=20):\n",
        "        feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
        "        feature_importance_df = feature_importance_df.sort_values('importance', ascending=False).head(top_n)\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.barplot(x='importance', y='feature', data=feature_importance_df, palette='viridis')\n",
        "        plt.title('Top {} Feature Importances'.format(top_n))\n",
        "        plt.xlabel('Importance')\n",
        "        plt.ylabel('Feature')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_calibration_curve(self, y_true, y_proba, n_bins=10):\n",
        "\n",
        "        combined = np.stack([y_proba, y_true], axis=-1)\n",
        "        combined = combined[np.argsort(combined[:, 0])]\n",
        "        sorted_probas = combined[:, 0]\n",
        "        sorted_true = combined[:, 1]\n",
        "\n",
        "        bins = np.linspace(0, 1, n_bins + 1)\n",
        "        bin_midpoints = bins[:-1] + (bins[1] - bins[0]) / 2\n",
        "        bin_assignments = np.digitize(sorted_probas, bins) - 1\n",
        "\n",
        "        bin_sums = np.bincount(bin_assignments, weights=sorted_probas, minlength=n_bins)\n",
        "        bin_true = np.bincount(bin_assignments, weights=sorted_true, minlength=n_bins)\n",
        "        bin_total = np.bincount(bin_assignments, minlength=n_bins)\n",
        "\n",
        "        fraction_of_positives = bin_true / bin_total\n",
        "        fraction_of_positives[np.isnan(fraction_of_positives)] = 0\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(bin_midpoints, fraction_of_positives, marker='o', label='Calibration Curve')\n",
        "        plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly Calibrated')\n",
        "\n",
        "        plt.xlabel('Predicted Probability')\n",
        "        plt.ylabel('Fraction of Positives')\n",
        "        plt.title('Calibration Curve')\n",
        "        plt.xlim(0, 1)\n",
        "        plt.ylim(0, 1)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_prediction_distribution(self, predictions, title=\"Distribution of Predictions\"):\n",
        "        \"\"\"Plots the distribution of model predictions.\"\"\"\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.histplot(predictions, kde=True, color='skyblue')\n",
        "        plt.title(title)\n",
        "        plt.xlabel('Predicted Probability')\n",
        "        plt.ylabel('Frequency')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_roc_curve(self, y_true, y_proba, title=\"ROC Curve\"):\n",
        "      \"\"\"Plots the Receiver Operating Characteristic (ROC) curve.\"\"\"\n",
        "      fpr, tpr, thresholds = roc_curve(y_true, y_proba)\n",
        "      roc_auc = auc(fpr, tpr)\n",
        "\n",
        "      plt.figure(figsize=(8, 6))\n",
        "      plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
        "      plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "      plt.xlabel('False Positive Rate')\n",
        "      plt.ylabel('True Positive Rate')\n",
        "      plt.title(title)\n",
        "      plt.xlim([0.0, 1.0])\n",
        "      plt.ylim([0.0, 1.05])\n",
        "      plt.legend(loc=\"lower right\")\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "    def run_all(self):\n",
        "        self.load_data()\n",
        "        self.create_models()\n",
        "        self.train_model()\n",
        "        self.predict_submission()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T05:10:07.765502Z",
          "iopub.execute_input": "2025-02-20T05:10:07.765752Z",
          "iopub.status.idle": "2025-02-20T05:10:07.790862Z",
          "shell.execute_reply.started": "2025-02-20T05:10:07.765735Z",
          "shell.execute_reply": "2025-02-20T05:10:07.790106Z"
        },
        "id": "lUK2XbXXJ2iS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    data_dir = '/kaggle/input/march-machine-learning-mania-2025/**'  # Or a local dir\n",
        "    predictor = TournamentPredictor(data_dir)\n",
        "    predictor.run_all()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T05:10:19.707262Z",
          "iopub.execute_input": "2025-02-20T05:10:19.707527Z",
          "iopub.status.idle": "2025-02-20T05:11:13.065324Z",
          "shell.execute_reply.started": "2025-02-20T05:10:19.707508Z",
          "shell.execute_reply": "2025-02-20T05:11:13.064284Z"
        },
        "id": "cMrTGp0YJ2iT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "a-i0trsHJ2iT"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}